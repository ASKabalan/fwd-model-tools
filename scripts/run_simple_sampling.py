#!/usr/bin/env python
"""
Simple field-based Bayesian inference workflow.

Complete workflow:
1. Define model: 16x16 initial condition field + 2 parameters (alpha, beta)
2. Forward model: produce linear, quadratic, and combined observables of the field
3. Generate synthetic observations by conditioning on true IC and parameters
4. Run MCMC sampling to infer IC and parameters from noisy observable
5. Analyze results: plot posteriors and IC comparison

Usage:
  python scripts/run_simple_sampling.py --output-dir output/simple --num-warmup 500 --num-samples 1000
  python scripts/run_simple_sampling.py --output-dir output/simple --plot-only  # analyze existing results
"""

import argparse
import os
import time
from pathlib import Path

os.environ["JAX_PLATFORM_NAME"] = "cpu"
os.environ["JAX_PLATFORMS"] = "cpu"
#os.environ["XLA_FLAGS"] = "--xla_force_host_platform_device_count=8"

import jax
import jax.numpy as jnp
import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt
import numpy as np
import numpyro
import numpyro.distributions as dist
from jaxpm.distributed import normal_field
from numpyro.handlers import condition, seed, trace

from fwd_model_tools.fields import DistributedNormal
from fwd_model_tools.plotting import plot_posterior
from fwd_model_tools.sampling import batched_sampling, load_samples

FIELD_SHAPE = (4, 4)
TRUE_ALPHA = 2.0
TRUE_BETA = 0.5
NOISE_STD = 0.1


def setup_sharding(pdims=(4, 2)):
    if jax.device_count() > 1:
        from jax.sharding import NamedSharding
        from jax.sharding import PartitionSpec as P

        mesh = jax.make_mesh(pdims, ("x", "y"))
        sharding = NamedSharding(mesh, P("x", "y"))
        print(f"Using sharding with mesh: {pdims}")
    else:
        sharding = None
        print("Single device mode - no sharding")

    return sharding


def setup_output_dir(output_dir):
    output_dir = Path(output_dir)
    plots_dir = output_dir / "plots"
    samples_dir = output_dir / "samples"
    data_dir = output_dir / "data"

    plots_dir.mkdir(parents=True, exist_ok=True)
    samples_dir.mkdir(parents=True, exist_ok=True)
    data_dir.mkdir(parents=True, exist_ok=True)

    return output_dir, plots_dir, samples_dir, data_dir


@jax.jit
def normalize_field(field, eps=1e-6):
    """Center and rescale a field to unit standard deviation to remove scale degeneracy."""
    centered = field - jnp.mean(field)
    std = jnp.std(centered)
    std = jnp.maximum(std, eps)
    return centered / std, std


def forward_model_components(ic, alpha, beta):
    """Compute separate forward-model contributions to make parameters identifiable."""
    linear_term = alpha * ic
    quadratic_term = beta * ic**2
    return linear_term, quadratic_term, linear_term + quadratic_term


def field_model(log_ic=False, sharding=None):
    ic_raw = numpyro.sample(
        "initial_conditions",
        DistributedNormal(jnp.zeros(FIELD_SHAPE),
                          jnp.ones(FIELD_SHAPE),
                          sharding=sharding))

    ic, ic_scale = normalize_field(ic_raw)
    # TODO: Sharding should be checked here in a test using some sort of a hook or debug tool
    #jax.debug.inspect_array_sharding(
    #    ic_raw, callback=lambda x: print(f"Sharding of raw IC: {x}"))
    #jax.debug.inspect_array_sharding(
    #    ic, callback=lambda x: print(f"Sharding of normalized IC: {x}"))

    alpha = numpyro.sample("alpha", dist.Uniform(0.5, 3.5))
    beta = numpyro.sample("beta", dist.Uniform(-1.0, 1.5))

    linear_term, quadratic_term, combined_term = forward_model_components(
        ic, alpha, beta)

    if log_ic:
        numpyro.deterministic("ic", ic)
        numpyro.deterministic("ic_scale", ic_scale)

    numpyro.sample("obs_linear", dist.Normal(linear_term, NOISE_STD))
    numpyro.sample("obs_quadratic", dist.Normal(quadratic_term, NOISE_STD))
    numpyro.sample("obs_combined", dist.Normal(combined_term, NOISE_STD))


def plot_field_comparison(true_field, samples_field, plots_dir):
    true_field = np.asarray(true_field)
    samples_field = np.asarray(samples_field)

    mean_field = samples_field.mean(axis=0)
    std_field = samples_field.std(axis=0)
    error_field = np.abs(mean_field - true_field)

    fig, axes = plt.subplots(1, 4, figsize=(20, 4))

    vmin_ic, vmax_ic = np.percentile(true_field, [2, 98])

    im0 = axes[0].imshow(true_field,
                         origin="lower",
                         cmap="viridis",
                         vmin=vmin_ic,
                         vmax=vmax_ic)
    axes[0].set_title("True IC")
    plt.colorbar(im0, ax=axes[0])

    im1 = axes[1].imshow(mean_field,
                         origin="lower",
                         cmap="viridis",
                         vmin=vmin_ic,
                         vmax=vmax_ic)
    axes[1].set_title("Posterior Mean IC")
    plt.colorbar(im1, ax=axes[1])

    im2 = axes[2].imshow(std_field, origin="lower", cmap="plasma")
    axes[2].set_title("Posterior Std IC")
    plt.colorbar(im2, ax=axes[2])

    im3 = axes[3].imshow(error_field, origin="lower", cmap="hot")
    axes[3].set_title("|Mean - True|")
    plt.colorbar(im3, ax=axes[3])

    plt.tight_layout()
    plt.savefig(plots_dir / "ic_comparison.png", dpi=150, bbox_inches="tight")
    plt.close()

    print("IC Error Statistics:")
    print(f"  Mean absolute error: {error_field.mean():.4f}")
    print(f"  Max absolute error: {error_field.max():.4f}")
    print(f"  Mean std: {std_field.mean():.4f}")


def generate_synthetic_observations(data_dir,
                                    plots_dir,
                                    sharding=None,
                                    magic_seed=42):
    print("\n" + "=" * 60)
    print("Step 1: Generating synthetic observations")
    print("=" * 60)

    key = jax.random.PRNGKey(magic_seed)
    true_ic_raw = normal_field(key, FIELD_SHAPE, sharding=sharding)
    print("✓ Generated initial conditions with sharding : \n")
    jax.debug.visualize_array_sharding(true_ic_raw)
    true_ic, true_ic_scale = normalize_field(true_ic_raw)

    def model_with_logging():
        return field_model(log_ic=True, sharding=sharding)

    conditioned_model = condition(model_with_logging, {
        "initial_conditions": true_ic_raw,
        "alpha": TRUE_ALPHA,
        "beta": TRUE_BETA
    })

    print("Tracing model to generate synthetic observable...")
    start_time = time.time()
    model_trace = trace(seed(conditioned_model, magic_seed)).get_trace()
    elapsed = time.time() - start_time
    print(f"✓ Model traced in {elapsed:.2f}s")

    true_obs_linear = model_trace["obs_linear"]["value"]
    true_obs_quadratic = model_trace["obs_quadratic"]["value"]
    true_obs_combined = true_obs_linear + true_obs_quadratic

    np.savez(
        data_dir / "true_data.npz",
        ic=np.asarray(true_ic),
        ic_raw=np.asarray(true_ic_raw),
        ic_scale=float(true_ic_scale),
        alpha=TRUE_ALPHA,
        beta=TRUE_BETA,
        obs_linear=np.asarray(true_obs_linear),
        obs_quadratic=np.asarray(true_obs_quadratic),
        obs_combined=np.asarray(true_obs_combined),
    )
    print(f"✓ Saved true data to {data_dir / 'true_data.npz'}")
    print(
        f"  True IC scale (std before normalization): {float(true_ic_scale):.4f}"
    )

    fig, axes = plt.subplots(1, 3, figsize=(16, 5))
    im0 = axes[0].imshow(np.asarray(true_ic), origin="lower", cmap="viridis")
    axes[0].set_title("True IC (unit std)")
    plt.colorbar(im0, ax=axes[0])

    im1 = axes[1].imshow(np.asarray(true_obs_linear),
                         origin="lower",
                         cmap="magma")
    axes[1].set_title("Linear observable")
    plt.colorbar(im1, ax=axes[1])

    im2 = axes[2].imshow(np.asarray(true_obs_quadratic),
                         origin="lower",
                         cmap="magma")
    axes[2].set_title("Quadratic observable")
    plt.colorbar(im2, ax=axes[2])

    fig.text(
        0.5,
        0.02,
        f"True values: α = {TRUE_ALPHA:.2f}, β = {TRUE_BETA:.2f}",
        ha="center",
        fontsize=14,
        bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.5),
    )

    plt.tight_layout()
    plt.subplots_adjust(bottom=0.1)
    plt.savefig(plots_dir / "true_data.png", dpi=150, bbox_inches="tight")
    plt.close()
    print(f"✓ Plotted true data to {plots_dir / 'true_data.png'}")

    return (
        {
            "obs_linear": true_obs_linear,
            "obs_quadratic": true_obs_quadratic,
            "obs_combined": true_obs_combined,
        },
        {
            "initial_conditions": true_ic_raw,
            "alpha": TRUE_ALPHA,
            "beta": TRUE_BETA
        },
    )


def run_mcmc_inference(true_obs,
                       samples_dir,
                       args,
                       sharding=None,
                       init_params=None):
    print("\n" + "=" * 60)
    print("Step 2: Running MCMC inference")
    print("=" * 60)
    print(f"running with sharding: {sharding}")

    def model_for_inference():
        return field_model(log_ic=True, sharding=sharding)

    observed_model = condition(
        model_for_inference,
        {
            "obs_linear": true_obs["obs_linear"],
            "obs_quadratic": true_obs["obs_quadratic"],
            "obs_combined": true_obs["obs_combined"],
        },
    )

    print(f"Sampling with {args.sampler} using {args.backend} backend")
    print(
        f"Warmup: {args.num_warmup}, Samples: {args.num_samples}, Batches: {args.batch_count}"
    )

    start_time = time.time()
    batched_sampling(
        model=observed_model,
        path=str(samples_dir),
        rng_key=jax.random.PRNGKey(args.seed),
        num_warmup=args.num_warmup,
        num_samples=args.num_samples,
        batch_count=args.batch_count,
        sampler=args.sampler,
        backend=args.backend,
        save=True,
        init_params=init_params,
    )
    elapsed = time.time() - start_time
    print(f"✓ MCMC sampling completed in {elapsed:.2f}s")


def analyze_results(samples_dir, data_dir, plots_dir, n_samples_plot=-1):
    print("\n" + "=" * 60)
    print("Step 3: Loading samples and plotting results")
    print("=" * 60)

    samples = load_samples(str(samples_dir))
    if n_samples_plot > 0:
        samples = jax.tree.map(lambda x: x[-n_samples_plot:], samples)
        print(f"Using last {n_samples_plot} samples for plotting")
    else:
        print("Using all samples for plotting")
    print(f"Loaded parameters: {list(samples.keys())}")

    true_data = np.load(data_dir / "true_data.npz")
    true_alpha = float(true_data["alpha"])
    true_beta = float(true_data["beta"])
    true_ic = true_data["ic"]

    print("\nPosterior Statistics:")
    print(f"True alpha: {true_alpha:.4f}")
    print(
        f"Inferred alpha: {samples['alpha'].mean():.4f} ± {samples['alpha'].std():.4f}"
    )
    print(f"True beta: {true_beta:.4f}")
    print(
        f"Inferred beta: {samples['beta'].mean():.4f} ± {samples['beta'].std():.4f}"
    )

    if "ic" in samples:
        print("\nPlotting IC comparison...")
        plot_field_comparison(true_ic, samples["ic"], plots_dir)
        print(f"✓ Plotted IC comparison to {plots_dir / 'ic_comparison.png'}")

    param_samples = {"alpha": samples["alpha"], "beta": samples["beta"]}
    true_param_values = {"alpha": true_alpha, "beta": true_beta}
    plot_posterior(param_samples,
                   plots_dir,
                   params=("alpha", "beta"),
                   true_values=true_param_values)
    print(
        f"✓ Plotted posteriors to {plots_dir / 'posterior_trace.png'} and {plots_dir / 'posterior_pair.png'}"
    )


def main():
    parser = argparse.ArgumentParser(
        description="Run simple field-based Bayesian inference workflow")
    parser.add_argument(
        "--output-dir",
        type=str,
        default="output/simple",
        help="Output directory for plots and samples",
    )
    parser.add_argument(
        "--num-warmup",
        type=int,
        default=50,
        help="Number of warmup steps for MCMC",
    )
    parser.add_argument(
        "--num-samples",
        type=int,
        default=10,
        help="Number of samples per batch",
    )
    parser.add_argument(
        "--batch-count",
        type=int,
        default=10,
        help="Number of batches to run",
    )
    parser.add_argument(
        "--sampler",
        type=str,
        choices=["NUTS", "HMC", "MCLMC"],
        default="NUTS",
        help="MCMC sampler to use",
    )
    parser.add_argument(
        "--backend",
        type=str,
        choices=["numpyro", "blackjax"],
        default="blackjax",
        help="Sampling backend",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Random seed",
    )
    parser.add_argument(
        "--plot-only",
        action="store_true",
        help=
        "Only analyze existing samples (skip data generation and sampling)",
    )
    parser.add_argument(
        "--n-samples-plot",
        type=int,
        default=-1,
        help=
        "Number of last samples to use for plotting (default: -1 for all samples)",
    )

    args = parser.parse_args()

    output_dir, plots_dir, samples_dir, data_dir = setup_output_dir(
        args.output_dir)

    print("=" * 60)
    print("Simple Field-Based Bayesian Inference Workflow")
    print("=" * 60)
    print(f"Field shape: {FIELD_SHAPE}")
    print(f"True alpha: {TRUE_ALPHA}")
    print(f"True beta: {TRUE_BETA}")
    print(f"Noise std: {NOISE_STD}")
    print(f"Output directory: {output_dir}")

    if args.plot_only:
        print("\n⚠ Plot-only mode: skipping data generation and sampling")
        analyze_results(samples_dir,
                        data_dir,
                        plots_dir,
                        n_samples_plot=args.n_samples_plot)
    else:
        sharding = setup_sharding()
        print("")

        true_obs, init_params = generate_synthetic_observations(
            data_dir, plots_dir, sharding=sharding, magic_seed=args.seed)

        run_mcmc_inference(true_obs,
                           samples_dir,
                           args,
                           sharding=sharding,
                           init_params=init_params)
        analyze_results(samples_dir,
                        data_dir,
                        plots_dir,
                        n_samples_plot=args.n_samples_plot)

    print("\n" + "=" * 60)
    print("✓ Workflow completed successfully!")
    print("=" * 60)


if __name__ == "__main__":
    main()
