{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lensing Bayesian Inference Workflow\n",
    "\n",
    "This notebook demonstrates a complete Bayesian inference workflow for weak gravitational lensing:\n",
    "\n",
    "1. **Gradient Analysis**: Compute and visualize gradients of the forward model w.r.t. cosmological parameters\n",
    "2. **Synthetic Observations**: Generate fiducial model predictions (convergence maps and lightcone)\n",
    "3. **MCMC Sampling**: Infer cosmological parameters from observations using NUTS/HMC/MCLMC\n",
    "4. **Results Analysis**: Plot posteriors and compare inferred vs. true initial conditions\n",
    "\n",
    "The notebook is structured to allow resuming from the MCMC sampling section without regenerating observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Important Notes\n\n**⚠️ NumPyro Sharding Limitation:**\nNumPyro does NOT support distributed sharding with checkpoint resumption. When resuming from a saved state, sharding information is lost. For distributed/sharded workflows, use `backend=\"blackjax\"`.\n\n**Spherical vs Flat Geometry:**\n- Spherical geometry uses HEALPix with visibility masking (only visible pixels are sampled)\n- Flat geometry uses Cartesian coordinates (all pixels within field)\n- Use `reconstruct_full_kappa()` to convert visible-pixel maps to full HEALPix maps for plotting",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\"\nos.environ[\"EQX_ON_ERROR\"] = \"nan\"\n\nif int(os.environ.get(\"SLURM_NTASKS\", 0)) > 1 or int(\n        os.environ.get(\"SLURM_NTASKS_PER_NODE\", 0)) > 1:\n    os.environ[\"VSCODE_PROXY_URI\"] = \"\"\n    os.environ[\"no_proxy\"] = \"\"\n    os.environ[\"NO_PROXY\"] = \"\"\n    del os.environ[\"VSCODE_PROXY_URI\"]\n    del os.environ[\"no_proxy\"]\n    del os.environ[\"NO_PROXY\"]\n    import jax\n\n    jax.distributed.initialize()\n\nimport jax\n\njax.config.update(\"jax_enable_x64\", False)\n\nimport time\nfrom pathlib import Path\n\nimport jax.numpy as jnp\nimport jax_cosmo as jc\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpyro.distributions as dist\nfrom diffrax import RecursiveCheckpointAdjoint\nfrom jaxpm.distributed import normal_field\nfrom numpyro.handlers import condition, seed, trace\nfrom scipy.stats import norm\n\nfrom fwd_model_tools import Configurations, Planck18, full_field_probmodel, reconstruct_full_kappa\nfrom fwd_model_tools.lensing_model import (\n    compute_box_size_from_redshift,\n    compute_max_redshift_from_box_size,\n    make_full_field_model,\n)\nfrom fwd_model_tools.plotting import (\n    plot_ic,\n    plot_kappa,\n    plot_lightcone,\n    plot_posterior,\n)\nfrom fwd_model_tools.sampling import batched_sampling, load_samples\n\nprint(f\"JAX devices: {jax.device_count()}\")\nprint(f\"JAX backend: {jax.default_backend()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Parameters\n",
    "\n",
    "Edit these parameters to customize the workflow. These correspond to the argparse arguments in `run_lensing_model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "output_dir = \"output_notebook\"\nbox_shape = (256, 256, 256)\nbox_size = None\nmax_redshift = None\ngeometry = \"spherical\"\nobserver_position = (0.5, 0.5, 0.0)\nnum_warmup = 50\nnum_samples = 50\nbatch_count = 2\nsampler = \"MCLMC\"  # \"NUTS\", \"HMC\", or \"MCLMC\"\nbackend = \"blackjax\"  # \"blackjax\" recommended for sharded runs (see Important Notes below)\nsigma_e = 0.3\nseed = 42\npdims = (4, 2)\n\ngradient_offset_omega_c = 0.005\ngradient_offset_sigma8 = 0.01"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def setup_output_dir(output_dir):\n    output_dir = Path(output_dir)\n    plots_dir = output_dir / \"plots\"\n    samples_dir = output_dir / \"samples\"\n    data_dir = output_dir / \"data\"\n\n    plots_dir.mkdir(parents=True, exist_ok=True)\n    samples_dir.mkdir(parents=True, exist_ok=True)\n    data_dir.mkdir(parents=True, exist_ok=True)\n\n    return output_dir, plots_dir, samples_dir, data_dir\n\n\ndef setup_sharding(pdims=(4, 2)):\n    if jax.device_count() > 1:\n        from jax.sharding import NamedSharding\n        from jax.sharding import PartitionSpec as P\n\n        mesh = jax.make_mesh(pdims, (\"x\", \"y\"))\n        sharding = NamedSharding(mesh, P(\"x\", \"y\"))\n        print(f\"Using sharding with mesh: {pdims}\")\n    else:\n        sharding = None\n        print(\"Single device mode - no sharding\")\n\n    return sharding\n\n\ndef create_redshift_distribution(\n    cosmo,\n    box_size=None,\n    observer_position=(0.5, 0.5, 0.5),\n    geometry=\"spherical\",\n    max_redshift=None,\n):\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Creating redshift distribution\")\n    print(\"=\" * 60)\n\n    if box_size is None and max_redshift is None:\n        raise ValueError(\"Either box_size or max_redshift must be provided\")\n\n    if box_size is None:\n        box_size = compute_box_size_from_redshift(cosmo, max_redshift,\n                                                  observer_position)\n        print(\n            f\"Auto-computed box size: {box_size} Mpc/h for max redshift {max_redshift}\"\n        )\n    elif max_redshift is None:\n        max_redshift = compute_max_redshift_from_box_size(\n            cosmo, box_size, observer_position)\n        print(\n            f\"Auto-computed max redshift: {max_redshift} for box size {box_size} Mpc/h\"\n        )\n\n    z = jnp.linspace(0, max_redshift, 1000)\n    z_centers = jnp.linspace(0.2, max_redshift - 0.01, 4)\n    z_centers = jnp.round(z_centers, 3)\n    print(f\"z_centers = {z_centers}\")\n\n    nz_shear = [\n        jc.redshift.kde_nz(\n            z,\n            norm.pdf(z, loc=z_center, scale=0.12),\n            bw=0.01,\n            zmax=max_redshift,\n            gals_per_arcmin2=g,\n        ) for z_center, g in zip(z_centers, [7, 8.5, 7.5, 7])\n    ]\n    nbins = len(nz_shear)\n\n    return nz_shear, nbins, max_redshift, box_size\n\n\noutput_dir_path, plots_dir, samples_dir, data_dir = setup_output_dir(output_dir)\nsharding = setup_sharding(pdims)\nfiducial_cosmology = Planck18()\n\nnz_shear, nbins, max_redshift, box_size = create_redshift_distribution(\n    fiducial_cosmology,\n    box_size,\n    observer_position=observer_position,\n    geometry=geometry,\n    max_redshift=max_redshift,\n)\n\nconfig = Configurations(\n    field_size=9.6,\n    field_npix=box_shape[0] if geometry == \"flat\" else 64,\n    box_shape=box_shape,\n    box_size=box_size,\n    density_plane_width=100.0,\n    density_plane_npix=box_shape[0],\n    nside=box_shape[0],\n    density_plane_smoothing=0.1,\n    nz_shear=nz_shear,\n    fiducial_cosmology=Planck18,\n    sigma_e=sigma_e,\n    priors={\n        \"Omega_c\": dist.Uniform(0.24, 0.28),\n        \"sigma8\": dist.Uniform(0.78, 0.82),\n    },\n    t0=0.1,\n    dt0=0.1,\n    t1=1.0,\n    min_redshift=0.01,\n    max_redshift=max_redshift,\n    sharding=sharding,\n    halo_size=0 if sharding is None else box_shape[0] // 8,\n    adjoint=RecursiveCheckpointAdjoint(4),\n    geometry=geometry,\n    observer_position=observer_position,\n    log_lightcone=False,\n    log_ic=False,\n)\n\nprint(\"\\nGenerating initial conditions...\")\ninitial_conditions = normal_field(jax.random.key(seed),\n                                  config.box_shape,\n                                  sharding=sharding)\nprint(\"✓ Initial conditions generated\")\nif sharding is not None:\n    jax.debug.visualize_array_sharding(initial_conditions[:, :, 0])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient Analysis\n",
    "\n",
    "Compute gradients of the forward model with respect to cosmological parameters to understand sensitivity.\n",
    "We evaluate gradients at 5 points: fiducial ± 2×offset, ± offset, and at the fiducial value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Creating forward model for gradient analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "forward_model = make_full_field_model(\n",
    "    box_shape=config.box_shape,\n",
    "    box_size=config.box_size,\n",
    "    nz_shear=config.nz_shear,\n",
    "    fiducial_cosmology=config.fiducial_cosmology,\n",
    "    field_size=config.field_size,\n",
    "    field_npix=config.field_npix,\n",
    "    t0=config.t0,\n",
    "    dt0=config.dt0,\n",
    "    t1=config.t1,\n",
    "    min_redshift=config.min_redshift,\n",
    "    max_redshift=config.max_redshift,\n",
    "    density_plane_width=config.density_plane_width,\n",
    "    density_plane_npix=config.density_plane_npix,\n",
    "    density_plane_smoothing=config.density_plane_smoothing,\n",
    "    sharding=config.sharding,\n",
    "    halo_size=config.halo_size,\n",
    "    adjoint=config.adjoint,\n",
    "    geometry=config.geometry,\n",
    "    observer_position=config.observer_position,\n",
    "    nside=config.nside,\n",
    "    log_lightcone=False,\n",
    "    log_ic=False,\n",
    ")\n",
    "\n",
    "print(\"✓ Forward model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_norm(forward_model, cosmo, nz_shear, ic, param_name, param_value):\n",
    "    cosmo_dict = {\n",
    "        \"Omega_c\": cosmo.Omega_c,\n",
    "        \"Omega_b\": cosmo.Omega_b,\n",
    "        \"h\": cosmo.h,\n",
    "        \"n_s\": cosmo.n_s,\n",
    "        \"sigma8\": cosmo.sigma8,\n",
    "        \"Omega_k\": cosmo.Omega_k,\n",
    "        \"w0\": cosmo.w0,\n",
    "        \"wa\": cosmo.wa,\n",
    "    }\n",
    "    cosmo_dict[param_name] = param_value\n",
    "    test_cosmo = jc.Cosmology(**cosmo_dict)\n",
    "    test_cosmo._workspace = {}\n",
    "    \n",
    "    def loss_fn(ic):\n",
    "        kappas, _, _ = forward_model(test_cosmo, nz_shear, ic)\n",
    "        return jnp.sum(jnp.array([jnp.sum(k**2) for k in kappas]))\n",
    "    \n",
    "    grad_fn = jax.grad(loss_fn)\n",
    "    grad = grad_fn(ic)\n",
    "    grad_norm = jnp.sqrt(jnp.sum(grad**2))\n",
    "    \n",
    "    return float(grad_norm)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Computing gradients for Omega_c\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "omega_c_fiducial = fiducial_cosmology.Omega_c\n",
    "omega_c_offsets = [-2 * gradient_offset_omega_c, -gradient_offset_omega_c, 0.0, \n",
    "                   gradient_offset_omega_c, 2 * gradient_offset_omega_c]\n",
    "omega_c_values = [omega_c_fiducial + offset for offset in omega_c_offsets]\n",
    "omega_c_grad_norms = []\n",
    "\n",
    "for i, (offset, value) in enumerate(zip(omega_c_offsets, omega_c_values)):\n",
    "    print(f\"Computing gradient {i+1}/5: Omega_c = {value:.4f} (offset = {offset:+.4f})\")\n",
    "    grad_norm = compute_gradient_norm(forward_model, fiducial_cosmology, nz_shear, \n",
    "                                     initial_conditions, \"Omega_c\", value)\n",
    "    omega_c_grad_norms.append(grad_norm)\n",
    "    print(f\"  Gradient norm: {grad_norm:.6e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Computing gradients for sigma8\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sigma8_fiducial = fiducial_cosmology.sigma8\n",
    "sigma8_offsets = [-2 * gradient_offset_sigma8, -gradient_offset_sigma8, 0.0, \n",
    "                  gradient_offset_sigma8, 2 * gradient_offset_sigma8]\n",
    "sigma8_values = [sigma8_fiducial + offset for offset in sigma8_offsets]\n",
    "sigma8_grad_norms = []\n",
    "\n",
    "for i, (offset, value) in enumerate(zip(sigma8_offsets, sigma8_values)):\n",
    "    print(f\"Computing gradient {i+1}/5: sigma8 = {value:.4f} (offset = {offset:+.4f})\")\n",
    "    grad_norm = compute_gradient_norm(forward_model, fiducial_cosmology, nz_shear, \n",
    "                                     initial_conditions, \"sigma8\", value)\n",
    "    sigma8_grad_norms.append(grad_norm)\n",
    "    print(f\"  Gradient norm: {grad_norm:.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(omega_c_offsets, omega_c_grad_norms, 'o-', linewidth=2, markersize=8, label='Gradient norm')\n",
    "axes[0].axvline(0, color='red', linestyle='--', alpha=0.5, label='Fiducial value')\n",
    "axes[0].set_xlabel('Omega_c offset', fontsize=12)\n",
    "axes[0].set_ylabel('Gradient norm', fontsize=12)\n",
    "axes[0].set_title(f'Gradient Sensitivity: Omega_c (fiducial = {omega_c_fiducial:.4f})', fontsize=13)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(sigma8_offsets, sigma8_grad_norms, 'o-', linewidth=2, markersize=8, label='Gradient norm', color='orange')\n",
    "axes[1].axvline(0, color='red', linestyle='--', alpha=0.5, label='Fiducial value')\n",
    "axes[1].set_xlabel('sigma8 offset', fontsize=12)\n",
    "axes[1].set_ylabel('Gradient norm', fontsize=12)\n",
    "axes[1].set_title(f'Gradient Sensitivity: sigma8 (fiducial = {sigma8_fiducial:.4f})', fontsize=13)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / 'gradient_sensitivity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Gradient sensitivity plots saved to {plots_dir / 'gradient_sensitivity.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Synthetic Observations\n",
    "\n",
    "Trace the fiducial model to create synthetic convergence maps and lightcone data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"Generating synthetic observations\")\nprint(\"=\" * 60)\n\nconfig_with_logging = config._replace(log_lightcone=True, log_ic=True)\nfull_field_basemodel = full_field_probmodel(config_with_logging)\n\nfiducial_model = condition(\n    full_field_basemodel,\n    {\n        \"Omega_c\": fiducial_cosmology.Omega_c,\n        \"sigma8\": fiducial_cosmology.sigma8,\n        \"initial_conditions\": initial_conditions,\n    },\n)\n\nprint(\"Tracing fiducial model to generate observables...\")\nstart_time = time.time()\nmodel_trace = trace(seed(fiducial_model, 0)).get_trace()\nelapsed = time.time() - start_time\nprint(f\"✓ Fiducial model traced in {elapsed:.2f}s\")\n\nnbins = len(config.nz_shear)\nkappa_keys = [f\"kappa_{i}\" for i in range(nbins)]\n\n# Keep visible-pixel kappas for inference\ntrue_kappas_visible = {key: model_trace[key][\"value\"] for key in kappa_keys}\n\n# Prepare full maps only for plotting (spherical geometry)\nif config.geometry == \"spherical\":\n    true_kappas_full = reconstruct_full_kappa(\n        true_kappas_visible, config.nside, config.observer_position\n    )\nelse:\n    true_kappas_full = true_kappas_visible\n\nnp.savez(\n    data_dir / \"true_kappas.npz\",\n    **true_kappas_visible,  # Save visible kappas for inference\n    Omega_c=fiducial_cosmology.Omega_c,\n    sigma8=fiducial_cosmology.sigma8,\n)\nprint(f\"✓ Saved true kappas to {data_dir / 'true_kappas.npz'}\")\n\ntrue_ic = np.asarray(model_trace[\"ic\"][\"value\"])\nnp.save(data_dir / \"true_ic.npy\", true_ic)\nprint(f\"✓ Saved true IC to {data_dir / 'true_ic.npy'}\")\n\ntrue_lightcone = np.asarray(model_trace[\"lightcone\"][\"value\"])\nnp.save(data_dir / \"true_lightcone.npy\", true_lightcone)\nprint(f\"✓ Saved true lightcone to {data_dir / 'true_lightcone.npy'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plot_lightcone(true_lightcone, plots_dir, spherical=(geometry == \"spherical\"))\nprint(f\"✓ Plotted lightcone to {plots_dir / 'lightcone.png'}\")\n\n# Use full maps for plotting\nkappa_array = np.stack([true_kappas_full[k] for k in kappa_keys])\nplot_kappa(kappa_array, plots_dir, spherical=(geometry == \"spherical\"))\nprint(f\"✓ Plotted kappa maps to {plots_dir / 'kappa_maps.png'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. MCMC Sampling (Resumable)\n\nThis section can be re-run independently to resume sampling or to sample with different parameters.\nThe `batched_sampling` function saves checkpoints that allow resuming from the last batch.\n\n**⚠️ Important:** If using distributed sharding with NumPyro backend, sharding will be lost on resumption. Use BlackJAX backend for distributed/sharded workflows (see Important Notes in README.md)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data = np.load(data_dir / \"true_kappas.npz\")\n",
    "true_kappas_loaded = {f\"kappa_{i}\": true_data[f\"kappa_{i}\"] for i in range(nbins)}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Setting up MCMC inference\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "config_inference = config._replace(log_lightcone=False, log_ic=True)\n",
    "full_field_basemodel = full_field_probmodel(config_inference)\n",
    "\n",
    "observed_model = condition(\n",
    "    full_field_basemodel,\n",
    "    {f\"kappa_{i}\": true_kappas_loaded[f\"kappa_{i}\"] for i in range(nbins)},\n",
    ")\n",
    "\n",
    "init_params = {\n",
    "    \"Omega_c\": fiducial_cosmology.Omega_c,\n",
    "    \"sigma8\": fiducial_cosmology.sigma8,\n",
    "    \"initial_conditions\": initial_conditions,\n",
    "}\n",
    "\n",
    "print(f\"Sampling with {sampler} using {backend} backend\")\n",
    "print(f\"Warmup: {num_warmup}, Samples: {num_samples}, Batches: {batch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_sampling(\n",
    "    model=observed_model,\n",
    "    path=str(samples_dir),\n",
    "    rng_key=jax.random.PRNGKey(seed),\n",
    "    num_warmup=num_warmup,\n",
    "    num_samples=num_samples,\n",
    "    batch_count=batch_count,\n",
    "    sampler=sampler,\n",
    "    backend=backend,\n",
    "    save=True,\n",
    "    init_params=init_params,\n",
    ")\n",
    "\n",
    "print(\"✓ MCMC sampling completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results and Analysis\n",
    "\n",
    "Load samples and generate posterior plots and initial condition comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Loading samples and analyzing results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_samples_plot = -1\n",
    "\n",
    "samples = load_samples(str(samples_dir))\n",
    "if n_samples_plot > 0:\n",
    "    samples = jax.tree.map(lambda x: x[-n_samples_plot:], samples)\n",
    "    print(f\"Using last {n_samples_plot} samples for plotting\")\n",
    "else:\n",
    "    print(f\"Using all {len(samples['Omega_c'])} samples for plotting\")\n",
    "\n",
    "print(f\"Loaded parameters: {list(samples.keys())}\")\n",
    "\n",
    "true_data = np.load(data_dir / \"true_kappas.npz\")\n",
    "true_Omega_c = float(true_data[\"Omega_c\"])\n",
    "true_sigma8 = float(true_data[\"sigma8\"])\n",
    "\n",
    "print(\"\\nPosterior Statistics:\")\n",
    "print(f\"True Omega_c: {true_Omega_c:.4f}\")\n",
    "print(f\"Inferred Omega_c: {samples['Omega_c'].mean():.4f} ± {samples['Omega_c'].std():.4f}\")\n",
    "print(f\"True sigma8: {true_sigma8:.4f}\")\n",
    "print(f\"Inferred sigma8: {samples['sigma8'].mean():.4f} ± {samples['sigma8'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if \"ic\" in samples:\n    true_ic = np.load(data_dir / \"true_ic.npy\")\n    plot_ic(true_ic, samples[\"ic\"], plots_dir)\n    print(f\"✓ Plotted IC comparison to {plots_dir / 'ic_comparison.png'}\")\n\nparam_samples = {\n    \"Omega_c\": samples[\"Omega_c\"],\n    \"sigma8\": samples[\"sigma8\"]\n}\ntrue_param_values = {\"Omega_c\": true_Omega_c, \"sigma8\": true_sigma8}\nplot_posterior(\n    param_samples,\n    plots_dir,\n    params=(\"Omega_c\", \"sigma8\"),\n    true_values=true_param_values  # Show true values on plots\n)\nprint(f\"✓ Plotted posteriors to {plots_dir / 'posterior_trace.png'} and {plots_dir / 'posterior_pair.png'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Workflow completed! Check the output directory for:\n",
    "- `plots/gradient_sensitivity.png`: Gradient analysis\n",
    "- `plots/kappa_maps.png`: Convergence maps\n",
    "- `plots/lightcone.png`: Density planes\n",
    "- `plots/ic_comparison.png`: Initial conditions comparison\n",
    "- `plots/posterior_trace.png` and `plots/posterior_pair.png`: Posterior distributions\n",
    "- `samples/`: MCMC samples (can be reloaded)\n",
    "- `data/`: True observations and initial conditions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}